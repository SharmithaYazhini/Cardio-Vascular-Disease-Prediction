# -*- coding: utf-8 -*-
"""Copy of Data cleaning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dTTZRvel7qSxxRBGvBg4LkayuhwG5wvo

#### Loading necessary packages
"""

import pandas as pd

df=pd.read_csv("cardio_train.csv",sep=";")

df.head()

df.shape

"""#### Checking for null values"""

df.isnull().sum()

"""There are no null values

#### Converting to appropriate data types
"""

for col in df.columns:
    print(col,df[col].dtype)

"""All the column are in the appropriate data type

#### Creating a new column for age in years
"""

df["age_y"]=round(df["age"]/365,0)

df.head()

df["age_y"].dtype

"""#### Renaming columns"""

df=df.rename(columns={"ap_hi":"systolic_bp","ap_lo":"diastolic_bp"})

df.head()

"""#### Outlier Detection"""

numerical_column=df[["height","weight","systolic_bp","diastolic_bp","age_y","age"]]

import matplotlib.pyplot as plt

for col in numerical_column:
    plt.figure(figsize=(8,6))
    df.boxplot(column=col)
    plt.title(f"Boxplot for column {col}")
    plt.ylabel("Values")
    plt.show()

"""#### Z-score"""

from scipy import stats

df_copy=df.copy()

z_score=stats.zscore(df_copy)
abs_z_score=abs(z_score)
outliers=(abs_z_score >3).all(axis=1)
df_no_outliers_copy = df_copy[~outliers]

print(df_copy.shape)
print(df_no_outliers_copy.shape)

print(df_copy[outliers])

"""#### Inter Quartile Range"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
outliers = ((df < lower_bound) | (df > upper_bound)).any(axis=1)
df_no_outliers = df[~outliers]

print(df_no_outliers.shape)
print(df.shape)

"""#### Exploratory Data Analysis"""

import seaborn as sns

df_categorical = df.loc[:,['cholesterol','gluc', 'smoke', 'alco', 'active']]
sns.countplot(x="variable", hue="value",data= pd.melt(df_categorical));

df_long = pd.melt(df, id_vars=['cardio'], value_vars=['cholesterol','gluc', 'smoke', 'alco', 'active'])
sns.catplot(x="variable", hue="value", col="cardio",
                data=df_long, kind="count");

df.groupby('gender')['height'].mean()

df['gender'].value_counts()

df['cardio'].value_counts(normalize=True)

pd.crosstab(df['cardio'],df['gender'],normalize=True)

df.describe()

import numpy as np

corr = df.corr()
cmap = sns.diverging_palette(220, 10, as_cmap=True)
# Generate a mask for the upper triangle
mask = np.zeros_like(corr, dtype=bool)
mask[np.triu_indices_from(mask)] = True

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))
# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,annot = True,
            square=True, linewidths=.5, cbar_kws={"shrink": .5});

"""#### Dropping the column id"""

df=df.drop(labels="id", axis=1)

"""#### Dropping duplicate values"""

df=df.drop_duplicates()

"""#### Train test split"""

from sklearn.model_selection import train_test_split

X=df[["age","gender", "height" , "weight" ,"systolic_bp", 'diastolic_bp','cholesterol', 'gluc', 'smoke', 'alco', 'active']]
y=df["cardio"]
X_train, X_test, y_train, y_test  = train_test_split(X, y,test_size=0.2, random_state=33)

"""#### Classifier Algorithms

#### Logistic Regression
"""

from sklearn.linear_model import LogisticRegression


# instantiate the model
logreg = LogisticRegression(solver='liblinear', random_state=0)


# fit the model
logreg.fit(X_train, y_train)

y_pred_test = logreg.predict(X_test)

from sklearn.metrics import accuracy_score

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))

"""#### Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

dt_model = DecisionTreeClassifier(random_state=33)

# Train the model on the training data
dt_model.fit(X_train, y_train)

y_pred = dt_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

"""#### Random forest"""

from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=33)

# Train the model on the training data
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test)

# Evaluate the model performance
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

"""#### KNN"""

from sklearn.neighbors import KNeighborsClassifier
knn_model = KNeighborsClassifier(n_neighbors=5)

# Train the model on the training data
knn_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = knn_model.predict(X_test)

# Evaluate the model performance
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

"""#### Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
nb_model = GaussianNB()

# Train the model on the training data
nb_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = nb_model.predict(X_test)

# Evaluate the model performance
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

"""#### ADA Boost"""

from sklearn.ensemble import AdaBoostClassifier
adaboost_model = AdaBoostClassifier(dt_model, n_estimators=50, random_state=42)

# Train the model on the training data
adaboost_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = adaboost_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"AdaBoost Accuracy: {accuracy:.2f}")

"""#### CAT Boost"""

pip install catboost

from catboost import CatBoostClassifier
catboost_model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, loss_function='Logloss', random_seed=42)

# Train the model on the training data
catboost_model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20, verbose=10)

# Make predictions on the test set
y_pred = catboost_model.predict(X_test)

# Evaluate the model performance
accuracy = accuracy_score(y_test, y_pred)
print(f"CatBoost Accuracy: {accuracy:.2f}")

filename = "catboost_model.cbm"
catboost_model.save_model(filename)

loaded_model = CatBoostClassifier()
loaded_model.load_model(filename)

"""Cat boost has the highest accuracy

#### Making a predictive System
"""

import pickle

"""#### Predictions"""

input_data=(21000,1,172,54,12,80,1,1,0,0,0)
input_data=np.asarray(input_data)
input_data=input_data.reshape(1,-1)
prediction=loaded_model.predict(input_data)
print(prediction)
if prediction ==0:
  print("No cardio vascular disease detected")
else:
  print("Cardio vascular disease detected")

from google.colab import drive
drive.mount('/content/drive')

input_data=(21000,0,162,84,190,23,1,1,1,1,1)
input_data=np.asarray(input_data)
input_data=input_data.reshape(1,-1)
prediction=loaded_model.predict(input_data)
print(prediction)
if prediction ==0:
  print("No cardio vascular disease detected")
else:
  print("Cardio vascular disease detected")

